{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d792338e-d52d-4933-a267-ed57542f7056",
   "metadata": {},
   "source": [
    "**5.- Entrena un modelo en Keras con capas convolucionales para predecir el valor diario de cierre de bolsa de Apple (puedes usar los datos que vimos en clase y que están en kaggle).  Utiliza de los datos de aprtura de 4 días anteriores para predecir el valor del día actual. Compáralo con un modelo con una capa lineal.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "637c349a-0275-4a10-8204-227ffdb8a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Layer, Dense, Conv1D, Flatten, Dropout, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4b10575-b0b0-4522-bb66-3edf471f03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos los datos de apple\n",
    "apple = pd.read_csv(r\"C:\\Users\\Carlos\\Documents\\MIA-X\\Modulo 4\\Machine Learning\\Redes Convulcionales\\CNN + RNN\\practica_rnn_cnn\\Stocks\\aa.us.txt\", delimiter=\",\")\n",
    "#Me quedo con los datos de apertura\n",
    "open_data = apple['Open'].values\n",
    "close_data = apple['Close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdc1eae2-0f85-4239-8e66-47f9103ef0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Me genero una matriz de ceros con las dimensiones que quiero, n_ejemplos x 5 datos. \n",
    "LAG = 5\n",
    "data = np.zeros((open_data.shape[0]- LAG, LAG))\n",
    "close = np.zeros((close_data.shape[0]- LAG, LAG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d15b931d-9027-4984-b899-5b9da5172155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserto en la matriz de ceros los datos que necesitamos con el LAG de 5\n",
    "for i in range(0,(open_data.shape[0] - LAG)):\n",
    "    data[i,:] = open_data[i:i+LAG]\n",
    "    close[i,:] = close_data[i:i+LAG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb6ea889-1d79-42fb-88f5-10109790a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos los datos en x_train, y_train, x_test, y_test, la columna 5 será nuestro label. \n",
    "n_data = data.shape[0]\n",
    "x_train = data[:round(n_data*0.7), :-1]\n",
    "y_train = data[:round(n_data*0.7), -1]\n",
    "x_test = close[round(n_data*0.7):, :-1]\n",
    "y_test = close[round(n_data*0.7):, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8719af-23fd-4357-84e7-5b6d23eaf170",
   "metadata": {},
   "source": [
    "Por la dimensión de nuestros datos, vamos a utilizar capas convulcionales 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "166ceb19-b718-4396-8a2e-9f0b0493df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos nuestro modelo\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(30, kernel_size = 3, input_shape=(4,1), activation = 'relu', padding='same'))\n",
    "model.add(Conv1D(10, kernel_size = 3, activation = 'relu', padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation = 'linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be053f15-e3ca-4bc7-b356-0f2cbec5d6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_11 (Conv1D)          (None, 4, 30)             120       \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 4, 10)             910       \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 40)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,071\n",
      "Trainable params: 1,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "edcbc718-e376-4410-8ac0-0f0b084ed317",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2faf903d-28ee-4c6d-9d77-40ee43b75bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "264/264 [==============================] - 0s 772us/step - loss: 1.5295\n",
      "Epoch 2/50\n",
      "264/264 [==============================] - 0s 768us/step - loss: 0.3482\n",
      "Epoch 3/50\n",
      "264/264 [==============================] - 0s 789us/step - loss: 0.3486\n",
      "Epoch 4/50\n",
      "264/264 [==============================] - 0s 787us/step - loss: 0.3398\n",
      "Epoch 5/50\n",
      "264/264 [==============================] - 0s 802us/step - loss: 0.3372\n",
      "Epoch 6/50\n",
      "264/264 [==============================] - 0s 802us/step - loss: 0.3211\n",
      "Epoch 7/50\n",
      "264/264 [==============================] - 0s 784us/step - loss: 0.3208\n",
      "Epoch 8/50\n",
      "264/264 [==============================] - 0s 768us/step - loss: 0.3179\n",
      "Epoch 9/50\n",
      "264/264 [==============================] - 0s 768us/step - loss: 0.3319\n",
      "Epoch 10/50\n",
      "264/264 [==============================] - 0s 772us/step - loss: 0.3159\n",
      "Epoch 11/50\n",
      "264/264 [==============================] - 0s 783us/step - loss: 0.3309\n",
      "Epoch 12/50\n",
      "264/264 [==============================] - 0s 783us/step - loss: 0.3338\n",
      "Epoch 13/50\n",
      "264/264 [==============================] - 0s 802us/step - loss: 0.3242\n",
      "Epoch 14/50\n",
      "264/264 [==============================] - 0s 886us/step - loss: 0.3172\n",
      "Epoch 15/50\n",
      "264/264 [==============================] - 0s 798us/step - loss: 0.3122\n",
      "Epoch 16/50\n",
      "264/264 [==============================] - 0s 801us/step - loss: 0.3133\n",
      "Epoch 17/50\n",
      "264/264 [==============================] - 0s 858us/step - loss: 0.3221\n",
      "Epoch 18/50\n",
      "264/264 [==============================] - 0s 798us/step - loss: 0.3204\n",
      "Epoch 19/50\n",
      "264/264 [==============================] - 0s 783us/step - loss: 0.3228\n",
      "Epoch 20/50\n",
      "264/264 [==============================] - 0s 798us/step - loss: 0.3119\n",
      "Epoch 21/50\n",
      "264/264 [==============================] - 0s 802us/step - loss: 0.3348\n",
      "Epoch 22/50\n",
      "264/264 [==============================] - 0s 943us/step - loss: 0.3194\n",
      "Epoch 23/50\n",
      "264/264 [==============================] - 0s 833us/step - loss: 0.3214\n",
      "Epoch 24/50\n",
      "264/264 [==============================] - 0s 802us/step - loss: 0.3111\n",
      "Epoch 25/50\n",
      "264/264 [==============================] - 0s 814us/step - loss: 0.3180\n",
      "Epoch 26/50\n",
      "264/264 [==============================] - 0s 799us/step - loss: 0.3139\n",
      "Epoch 27/50\n",
      "264/264 [==============================] - 0s 817us/step - loss: 0.3142\n",
      "Epoch 28/50\n",
      "264/264 [==============================] - 0s 802us/step - loss: 0.3150\n",
      "Epoch 29/50\n",
      "264/264 [==============================] - 0s 844us/step - loss: 0.3114\n",
      "Epoch 30/50\n",
      "264/264 [==============================] - 0s 1ms/step - loss: 0.3216\n",
      "Epoch 31/50\n",
      "264/264 [==============================] - 0s 943us/step - loss: 0.3226\n",
      "Epoch 32/50\n",
      "264/264 [==============================] - 0s 802us/step - loss: 0.3199\n",
      "Epoch 33/50\n",
      "264/264 [==============================] - 0s 802us/step - loss: 0.3136\n",
      "Epoch 34/50\n",
      "264/264 [==============================] - 0s 791us/step - loss: 0.3159\n",
      "Epoch 35/50\n",
      "264/264 [==============================] - 0s 812us/step - loss: 0.3092\n",
      "Epoch 36/50\n",
      "264/264 [==============================] - 0s 802us/step - loss: 0.3068\n",
      "Epoch 37/50\n",
      "264/264 [==============================] - 0s 791us/step - loss: 0.3149\n",
      "Epoch 38/50\n",
      "264/264 [==============================] - 0s 945us/step - loss: 0.3041\n",
      "Epoch 39/50\n",
      "264/264 [==============================] - 0s 848us/step - loss: 0.3040\n",
      "Epoch 40/50\n",
      "264/264 [==============================] - 0s 951us/step - loss: 0.3072\n",
      "Epoch 41/50\n",
      "264/264 [==============================] - 0s 1ms/step - loss: 0.3205\n",
      "Epoch 42/50\n",
      "264/264 [==============================] - 0s 1ms/step - loss: 0.3111\n",
      "Epoch 43/50\n",
      "264/264 [==============================] - 0s 989us/step - loss: 0.3188\n",
      "Epoch 44/50\n",
      "264/264 [==============================] - 0s 928us/step - loss: 0.3065\n",
      "Epoch 45/50\n",
      "264/264 [==============================] - 0s 848us/step - loss: 0.3123\n",
      "Epoch 46/50\n",
      "264/264 [==============================] - 0s 875us/step - loss: 0.3093\n",
      "Epoch 47/50\n",
      "264/264 [==============================] - 0s 855us/step - loss: 0.3030\n",
      "Epoch 48/50\n",
      "264/264 [==============================] - 0s 848us/step - loss: 0.3141\n",
      "Epoch 49/50\n",
      "264/264 [==============================] - 0s 851us/step - loss: 0.3030\n",
      "Epoch 50/50\n",
      "264/264 [==============================] - 0s 840us/step - loss: 0.3074\n"
     ]
    }
   ],
   "source": [
    "history_convulcional = model.fit(x_train, y_train,  epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e75c4afd-93bd-401b-8ec6-a54b04add23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 602us/step - loss: 0.7447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7447189688682556"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9471f6d-8855-461b-89cf-afdead1921eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 30)                150       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 15)                465       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 631\n",
      "Trainable params: 631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Definimos nuestro modelo lineal\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30, input_shape=(4,)))\n",
    "model.add(Dense(15))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "          \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c799575-9e8a-4f1f-9402-bde1bc975a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab8a7306-d9dc-446e-a3e9-106d1183d195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "264/264 [==============================] - 0s 650us/step - loss: 1.2064\n",
      "Epoch 2/50\n",
      "264/264 [==============================] - 0s 646us/step - loss: 0.5225\n",
      "Epoch 3/50\n",
      "264/264 [==============================] - 0s 639us/step - loss: 0.4596\n",
      "Epoch 4/50\n",
      "264/264 [==============================] - 0s 639us/step - loss: 0.4387\n",
      "Epoch 5/50\n",
      "264/264 [==============================] - 0s 662us/step - loss: 0.3924\n",
      "Epoch 6/50\n",
      "264/264 [==============================] - 0s 643us/step - loss: 0.3972\n",
      "Epoch 7/50\n",
      "264/264 [==============================] - 0s 617us/step - loss: 0.3758\n",
      "Epoch 8/50\n",
      "264/264 [==============================] - 0s 627us/step - loss: 0.3749\n",
      "Epoch 9/50\n",
      "264/264 [==============================] - 0s 627us/step - loss: 0.3801\n",
      "Epoch 10/50\n",
      "264/264 [==============================] - 0s 616us/step - loss: 0.3766\n",
      "Epoch 11/50\n",
      "264/264 [==============================] - 0s 616us/step - loss: 0.3525\n",
      "Epoch 12/50\n",
      "264/264 [==============================] - 0s 608us/step - loss: 0.3554\n",
      "Epoch 13/50\n",
      "264/264 [==============================] - 0s 624us/step - loss: 0.3562\n",
      "Epoch 14/50\n",
      "264/264 [==============================] - 0s 624us/step - loss: 0.3383\n",
      "Epoch 15/50\n",
      "264/264 [==============================] - 0s 608us/step - loss: 0.3286\n",
      "Epoch 16/50\n",
      "264/264 [==============================] - 0s 646us/step - loss: 0.3489\n",
      "Epoch 17/50\n",
      "264/264 [==============================] - 0s 620us/step - loss: 0.3495\n",
      "Epoch 18/50\n",
      "264/264 [==============================] - 0s 616us/step - loss: 0.3369\n",
      "Epoch 19/50\n",
      "264/264 [==============================] - 0s 620us/step - loss: 0.3357\n",
      "Epoch 20/50\n",
      "264/264 [==============================] - 0s 620us/step - loss: 0.3466\n",
      "Epoch 21/50\n",
      "264/264 [==============================] - 0s 627us/step - loss: 0.3320\n",
      "Epoch 22/50\n",
      "264/264 [==============================] - 0s 620us/step - loss: 0.3301\n",
      "Epoch 23/50\n",
      "264/264 [==============================] - 0s 620us/step - loss: 0.3204\n",
      "Epoch 24/50\n",
      "264/264 [==============================] - 0s 622us/step - loss: 0.3331\n",
      "Epoch 25/50\n",
      "264/264 [==============================] - 0s 620us/step - loss: 0.3384\n",
      "Epoch 26/50\n",
      "264/264 [==============================] - 0s 732us/step - loss: 0.3180\n",
      "Epoch 27/50\n",
      "264/264 [==============================] - 0s 616us/step - loss: 0.3164\n",
      "Epoch 28/50\n",
      "264/264 [==============================] - 0s 616us/step - loss: 0.3297\n",
      "Epoch 29/50\n",
      "264/264 [==============================] - 0s 608us/step - loss: 0.3125\n",
      "Epoch 30/50\n",
      "264/264 [==============================] - 0s 608us/step - loss: 0.3260\n",
      "Epoch 31/50\n",
      "264/264 [==============================] - 0s 639us/step - loss: 0.3216\n",
      "Epoch 32/50\n",
      "264/264 [==============================] - 0s 600us/step - loss: 0.3240\n",
      "Epoch 33/50\n",
      "264/264 [==============================] - 0s 608us/step - loss: 0.3467\n",
      "Epoch 34/50\n",
      "264/264 [==============================] - 0s 612us/step - loss: 0.3351\n",
      "Epoch 35/50\n",
      "264/264 [==============================] - 0s 605us/step - loss: 0.3206\n",
      "Epoch 36/50\n",
      "264/264 [==============================] - 0s 601us/step - loss: 0.3302\n",
      "Epoch 37/50\n",
      "264/264 [==============================] - 0s 612us/step - loss: 0.3284\n",
      "Epoch 38/50\n",
      "264/264 [==============================] - 0s 688us/step - loss: 0.3197\n",
      "Epoch 39/50\n",
      "264/264 [==============================] - 0s 608us/step - loss: 0.3286\n",
      "Epoch 40/50\n",
      "264/264 [==============================] - 0s 612us/step - loss: 0.3083\n",
      "Epoch 41/50\n",
      "264/264 [==============================] - 0s 605us/step - loss: 0.3134\n",
      "Epoch 42/50\n",
      "264/264 [==============================] - 0s 597us/step - loss: 0.3180\n",
      "Epoch 43/50\n",
      "264/264 [==============================] - 0s 620us/step - loss: 0.3254\n",
      "Epoch 44/50\n",
      "264/264 [==============================] - 0s 616us/step - loss: 0.3325\n",
      "Epoch 45/50\n",
      "264/264 [==============================] - 0s 605us/step - loss: 0.3132\n",
      "Epoch 46/50\n",
      "264/264 [==============================] - 0s 605us/step - loss: 0.3115\n",
      "Epoch 47/50\n",
      "264/264 [==============================] - 0s 612us/step - loss: 0.3313\n",
      "Epoch 48/50\n",
      "264/264 [==============================] - 0s 608us/step - loss: 0.3162\n",
      "Epoch 49/50\n",
      "264/264 [==============================] - 0s 601us/step - loss: 0.3165\n",
      "Epoch 50/50\n",
      "264/264 [==============================] - 0s 616us/step - loss: 0.3211\n"
     ]
    }
   ],
   "source": [
    "history_lineal = model.fit(x_train, y_train,  epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db9cc091-9546-4d82-86ae-94bee20293df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 549us/step - loss: 0.7039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7038784027099609"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f03f556-afeb-4ff2-9b85-7a1a32b90a7d",
   "metadata": {},
   "source": [
    "Analizando los resultados, vemos como la capa densa lo hace un poco mejor que la capa conv1D. Seguramente si optimizaramos hiperparámetros o añadieramos técnicas de regularización se podría obtener un resultado distinto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
